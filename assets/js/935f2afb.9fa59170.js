"use strict";(self.webpackChunkreact_native_website=self.webpackChunkreact_native_website||[]).push([[53],{1109:function(e){e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":"unreleased","badge":true,"className":"docs-version-current","isLast":false,"docsSidebars":{},"docs":{"Accelarators":{"id":"Accelarators","title":"Accelarators","description":""},"App-Deployment":{"id":"App-Deployment","title":"App Deployment","description":"1.\\tNavigate to deploy section from sidebar on the platform."},"Architecture-Overview":{"id":"Architecture-Overview","title":"Architecture Overview","description":""},"Backup-and-Recovery":{"id":"Backup-and-Recovery","title":"Backup and Recovery","description":""},"core-concept":{"id":"core-concept","title":"Core Concept","description":""},"Data-Labeling-Use-Case":{"id":"Data-Labeling-Use-Case","title":"Data Labeling Use Case","description":""},"Drift":{"id":"Drift","title":"Drift","description":"ADWIN"},"End-to-End-Training-Video":{"id":"End-to-End-Training-Video","title":"End to End Training Video","description":""},"End-to-End-use-case-with-Feature-Store":{"id":"End-to-End-use-case-with-Feature-Store","title":"End to End use case with Feature Store","description":""},"Experiment-Operations":{"id":"Experiment-Operations","title":"Experiment Operations","description":"Create a New Experiment"},"Experiments":{"id":"Experiments","title":"Experiments","description":""},"Feature-Store":{"id":"Feature-Store","title":"Feature Store","description":"Initialize Feature Store"},"File-Manager":{"id":"File-Manager","title":"File Manager","description":"The Console Object Browser section displays all buckets and objects to which the authenticated user has access."},"From-Notebook-to-Kubeflow-pipeline-using-Katonic-Deployment-Panel":{"id":"From-Notebook-to-Kubeflow-pipeline-using-Katonic-Deployment-Panel","title":"From Notebook to Kubeflow pipeline using Katonic Deployment Panel","description":""},"From-Notebook-to-Kubeflow-Pipeline-using-Katonic-SDK":{"id":"From-Notebook-to-Kubeflow-Pipeline-using-Katonic-SDK","title":"From Notebook to Kubeflow Pipeline using Katonic SDK","description":""},"From-Notebook-to-Kubeflow-Pipeline-using-Katonic-Studio":{"id":"From-Notebook-to-Kubeflow-Pipeline-using-Katonic-Studio","title":"From-Notebook-to-Kubeflow-Pipeline-using-Katonic-Studio","description":""},"Git-Integration":{"id":"Git-Integration","title":"Git Integration","description":"You may commit any changes you make in a workspace back to GitHub. We recommend using the JupyterLab Git extension, which comes preinstalled in Katonic workspaces by default."},"How-to-train-a-using-custom-Model":{"id":"How-to-train-a-using-custom-Model","title":"How to train a using custom Model","description":""},"Installation-Process":{"id":"Installation-Process","title":"Installation Process","description":""},"integration-with-existing-apps":{"id":"integration-with-existing-apps","title":"Integration with Existing Apps","description":""},"Katonic-Automated-Pipeline-Deplyment":{"id":"Katonic-Automated-Pipeline-Deplyment","title":"Katonic Automated Pipeline Deplyment","description":"The Katonic Automated Pipeline Deployment component gives the data scientists the tools they need to orchestrate end-to-end ML workflows. Katonic Automated Pipeline Deployment provides a GUI in the form of a JupyterLab extension."},"Katonic-Studio":{"id":"Katonic-Studio","title":"Katonic Studio","description":""},"Logging-and-Monitoring":{"id":"Logging-and-Monitoring","title":"Logging and Monitoring","description":""},"Model-Deployment":{"id":"Model-Deployment","title":"Model Deployment","description":"Model deployment is the process of putting machine learning models into production. This makes the model\u2019s predictions available to users, developers or systems, so they can make business decisions based on data, interact with their application (like recognize a face in an image) and so on."},"Model-Monitoring":{"id":"Model-Monitoring","title":"Model Monitoring","description":""},"Model-Registry":{"id":"Model-Registry","title":"Model Registry","description":""},"pipeline-operations":{"id":"pipeline-operations","title":"Pipelines Operations","description":"Initiate kfp client"},"Pipelines":{"id":"Pipelines","title":"Pipelines","description":"Pipelines are components that orchestrates machine learning applications. Orchestration is necessary because a typical machine learning implementation uses a combination of tools to prepare data, train the model, evaluate performance, and deploy. By formalizing the steps and their sequencing in code, pipelines allow users to formally capture all of the data processing steps, ensuring their reproducibility and auditability, and training and deployment steps."},"Publish-a-Dash-App":{"id":"Publish-a-Dash-App","title":"Publish a Dash App","description":"Overview"},"Publish-a-Streamlit-App":{"id":"Publish-a-Streamlit-App","title":"Publish a Streamlit App","description":"Overview"},"publishing-to-app-store":{"id":"publishing-to-app-store","title":"Publishing to Apple App Store","description":"The publishing process is the same as any other native iOS app, with some additional considerations to take into account."},"quickstart":{"id":"quickstart","title":"Quickstart","description":""},"readmesdk":{"id":"readmesdk","title":"Intoduction","description":"The document guides data scientists and developers to build ML applications on the Katonic MLOps platform. Katonic SDK is a repository of abstract python classes and libraries. The Katonic Python SDK was developed in Python and is designed to help data scientists and developers interact with Katonic from their code, experiments and models. Through the SDK, you can create experiments, manage models, automate your machine learning pipeline and more."},"Registry-Operation":{"id":"Registry-Operation","title":"Registry Operation","description":"Registering Model"},"Requirements":{"id":"Requirements","title":"Requirements","description":""},"Security":{"id":"Security","title":"Security","description":""},"Service-Mesh":{"id":"Service-Mesh","title":"Service Mesh","description":""},"Services":{"id":"Services","title":"Services","description":""},"Sizing-Infrastructure-for-Katonic":{"id":"Sizing-Infrastructure-for-Katonic","title":"Sizing Infrastructure for Katonic","description":""},"Software":{"id":"Software","title":"Software","description":""},"Upgrade-Katonic":{"id":"Upgrade-Katonic","title":"Upgrade Katonic","description":""},"User-Management":{"id":"User-Management","title":"User Management","description":""},"User-Operations":{"id":"User-Operations","title":"User Operations","description":""},"Workspace-Operations":{"id":"Workspace-Operations","title":"Workspace Operations","description":""},"Workspaces":{"id":"Workspaces","title":"Workspaces","description":"A Katonic workspace is an interactive environment for developing and running code. You can conduct research, analyze data, train models, and more. Use workspaces to work in the development environment of your choice, like Jupyter notebooks, RStudio , VS Code, and many other customizable environments. The environment is pre-configured (meaning all your dependencies are preinstalled). All the files and data in your workspace will be preserved for you, across restarts. Your workspace has automatic version control and scalable compute available, so that you can use unlimited compute resources to do your data science research."}}}')}}]);