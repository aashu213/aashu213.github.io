"use strict";(self.webpackChunkkatonic_dev=self.webpackChunkkatonic_dev||[]).push([[1268],{35318:function(e,t,i){i.d(t,{Zo:function(){return c},kt:function(){return h}});var n=i(27378);function r(e,t,i){return t in e?Object.defineProperty(e,t,{value:i,enumerable:!0,configurable:!0,writable:!0}):e[t]=i,e}function a(e,t){var i=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),i.push.apply(i,n)}return i}function l(e){for(var t=1;t<arguments.length;t++){var i=null!=arguments[t]?arguments[t]:{};t%2?a(Object(i),!0).forEach((function(t){r(e,t,i[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(i)):a(Object(i)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(i,t))}))}return e}function p(e,t){if(null==e)return{};var i,n,r=function(e,t){if(null==e)return{};var i,n,r={},a=Object.keys(e);for(n=0;n<a.length;n++)i=a[n],t.indexOf(i)>=0||(r[i]=e[i]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)i=a[n],t.indexOf(i)>=0||Object.prototype.propertyIsEnumerable.call(e,i)&&(r[i]=e[i])}return r}var o=n.createContext({}),s=function(e){var t=n.useContext(o),i=t;return e&&(i="function"==typeof e?e(t):l(l({},t),e)),i},c=function(e){var t=s(e.components);return n.createElement(o.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var i=e.components,r=e.mdxType,a=e.originalType,o=e.parentName,c=p(e,["components","mdxType","originalType","parentName"]),d=s(i),h=r,f=d["".concat(o,".").concat(h)]||d[h]||u[h]||a;return i?n.createElement(f,l(l({ref:t},c),{},{components:i})):n.createElement(f,l({ref:t},c))}));function h(e,t){var i=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=i.length,l=new Array(a);l[0]=d;var p={};for(var o in t)hasOwnProperty.call(t,o)&&(p[o]=t[o]);p.originalType=e,p.mdxType="string"==typeof e?e:r,l[1]=p;for(var s=2;s<a;s++)l[s]=i[s];return n.createElement.apply(null,l)}return n.createElement.apply(null,i)}d.displayName="MDXCreateElement"},56221:function(e,t,i){i.r(t),i.d(t,{frontMatter:function(){return d},contentTitle:function(){return h},metadata:function(){return f},toc:function(){return m},default:function(){return k}});var n=i(35318),r=Object.defineProperty,a=Object.defineProperties,l=Object.getOwnPropertyDescriptors,p=Object.getOwnPropertySymbols,o=Object.prototype.hasOwnProperty,s=Object.prototype.propertyIsEnumerable,c=(e,t,i)=>t in e?r(e,t,{enumerable:!0,configurable:!0,writable:!0,value:i}):e[t]=i,u=(e,t)=>{for(var i in t||(t={}))o.call(t,i)&&c(e,i,t[i]);if(p)for(var i of p(t))s.call(t,i)&&c(e,i,t[i]);return e};const d={id:"Pipelines",title:"Pipelines"},h=void 0,f={unversionedId:"Pipelines",id:"version-3.1/Pipelines",title:"Pipelines",description:"Pipelines are components that orchestrates machine learning applications. Orchestration is necessary because a typical machine learning implementation uses a combination of tools to prepare data, train the model, evaluate performance, and deploy. By formalizing the steps and their sequencing in code, pipelines allow users to formally capture all of the data processing steps, ensuring their reproducibility and auditability, and training and deployment steps.",source:"@site/versioned_docs/version-3.1/Pipelines.md",sourceDirName:".",slug:"/Pipelines",permalink:"/Pipelines",tags:[],version:"3.1",frontMatter:{id:"Pipelines",title:"Pipelines"},sidebar:"User Guide",previous:{title:"Model Registry",permalink:"/Model-Registry"},next:{title:"Katonic Automated Pipeline Deplyment",permalink:"/Katonic-Automated-Pipeline-Deplyment"}},m=[{value:"What is a pipeline?",id:"what-is-a-pipeline",children:[],level:3},{value:"Getting Started with Pipelines",id:"getting-started-with-pipelines",children:[{value:"The runtime execution graph of the pipeline",id:"the-runtime-execution-graph-of-the-pipeline",children:[],level:5},{value:"Pipeline input data on the Pipelines UI",id:"pipeline-input-data-on-the-pipelines-ui",children:[],level:5},{value:"Outputs from the pipeline",id:"outputs-from-the-pipeline",children:[],level:5},{value:"At a high level, the execution of a pipeline proceeds as follows:",id:"at-a-high-level-the-execution-of-a-pipeline-proceeds-as-follows",children:[],level:5}],level:3},{value:"PIPELINES UI",id:"pipelines-ui",children:[{value:"Open pipelines from the sidebar to see the different sections present in it.",id:"open-pipelines-from-the-sidebar-to-see-the-different-sections-present-in-it",children:[],level:5},{value:"The following sections are present under pipelines \u2013",id:"the-following-sections-are-present-under-pipelines-",children:[],level:5}],level:2},{value:"Experiment",id:"experiment",children:[{value:"To create an experiment from the Pipelines UI:",id:"to-create-an-experiment-from-the-pipelines-ui",children:[],level:4}],level:2},{value:"Pipelines",id:"pipelines",children:[{value:"To upload a pipeline:",id:"to-upload-a-pipeline",children:[],level:4}],level:2},{value:"Run",id:"run",children:[{value:"To create a run:",id:"to-create-a-run",children:[],level:4}],level:2},{value:"Recurring Run",id:"recurring-run",children:[{value:"To create a recurring run:",id:"to-create-a-recurring-run",children:[],level:4}],level:2},{value:"Archive",id:"archive",children:[],level:2}],g={toc:m};function k(e){var t,r=e,{components:c}=r,d=((e,t)=>{var i={};for(var n in e)o.call(e,n)&&t.indexOf(n)<0&&(i[n]=e[n]);if(null!=e&&p)for(var n of p(e))t.indexOf(n)<0&&s.call(e,n)&&(i[n]=e[n]);return i})(r,["components"]);return(0,n.kt)("wrapper",(t=u(u({},g),d),a(t,l({components:c,mdxType:"MDXLayout"}))),(0,n.kt)("p",null,"Pipelines are components that orchestrates machine learning applications. Orchestration is necessary because a typical machine learning implementation uses a combination of tools to prepare data, train the model, evaluate performance, and deploy. By formalizing the steps and their sequencing in code, pipelines allow users to formally capture all of the data processing steps, ensuring their reproducibility and auditability, and training and deployment steps. "),(0,n.kt)("h3",u({},{id:"what-is-a-pipeline"}),"What is a pipeline?"),(0,n.kt)("p",null,"A pipeline is a description of an ML workflow, including all of the components in the workflow and how they combine in the form of a graph. The pipeline includes the definition of the inputs (parameters) required to run the pipeline and the inputs and outputs of each component. "),(0,n.kt)("p",null,"A pipeline component is a self-contained set of user code, packaged as a Docker image, that performs one step in the pipeline. For example, a component can be responsible for data pre-processing, data transformation, model training, and so on. "),(0,n.kt)("h3",u({},{id:"getting-started-with-pipelines"}),"Getting Started with Pipelines"),(0,n.kt)("p",null,"The Pipelines UI consists of: "),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"A UI for managing and tracking pipelines and their execution ")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"An engine for scheduling a pipeline\u2019s execution ")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"An SDK for defining, building, and deploying pipelines in Python ")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Notebook support for using the SDK and pipeline execution "))),(0,n.kt)("h5",u({},{id:"the-runtime-execution-graph-of-the-pipeline"}),"The runtime execution graph of the pipeline"),(0,n.kt)("p",null,"A graph is a pictorial representation in the Pipelines UI of the runtime execution of a pipeline. The graph shows the steps that a pipeline run has executed or is executing, with arrows indicating the parent/child relationships between the pipeline components represented by each step. The graph is viewable as soon as the run begins. Each node within the graph corresponds to a step within the pipeline and is labelled accordingly. "),(0,n.kt)("p",null,"The screenshot below shows the example pipeline\u2019s runtime execution graph in the Pipelines UI: "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(90571).Z})),(0,n.kt)("p",null,"At the top right of each node is an icon indicating its status: running, succeeded, failed, or skipped. (A node can be skipped when its parent contains a conditional clause.) "),(0,n.kt)("h5",u({},{id:"pipeline-input-data-on-the-pipelines-ui"}),"Pipeline input data on the Pipelines UI"),(0,n.kt)("p",null,"The partial screenshot below shows the Pipelines UI for kicking off a run of the pipeline. The pipeline definition in your code determines which parameters appear in the UI form. The pipeline definition can also set default values for the parameters: "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(31332).Z})),(0,n.kt)("h5",u({},{id:"outputs-from-the-pipeline"}),"Outputs from the pipeline"),(0,n.kt)("p",null,"The following screenshot show example of the pipeline outputs visible on the Pipelines UI. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(73954).Z})),(0,n.kt)("h5",u({},{id:"at-a-high-level-the-execution-of-a-pipeline-proceeds-as-follows"}),"At a high level, the execution of a pipeline proceeds as follows:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Python SDK: You create components or specify a pipeline using the Pipelines domain-specific language (DSL). ")),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"DSL compiler: The DSL compiler transforms your pipeline\u2019s Python code into a static configuration (YAML). ")),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Pipeline Service: You call the Pipeline Service to create a pipeline run from the static configuration. ")),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Kubernetes resources: The Pipeline Service calls the Kubernetes API server to create the necessary Kubernetes resources (CRDs) to run the pipeline. ")),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Orchestration controllers: A set of orchestration controllers execute the containers needed to complete the pipeline. The containers execute within Kubernetes Pods on virtual machines. An example controller is the Argo Workflow controller, which orchestrates task-driven workflows. ")),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Artifact storage: The Pods store two kinds of data: "),(0,n.kt)("blockquote",{parentName:"li"},(0,n.kt)("p",{parentName:"blockquote"},"Metadata: Experiments, jobs, pipeline runs, and single scalar metrics. Metric data is aggregated for the purpose of sorting and filtering. Pipelines stores the metadata in a MySQL database. ")),(0,n.kt)("blockquote",{parentName:"li"},(0,n.kt)("p",{parentName:"blockquote"},"Artifacts: Pipeline packages, views, and large-scale metrics (time series). Use large-scale metrics to debug a pipeline run or investigate an individual run\u2019s performance. Pipelines stores the artifacts in an artifact store like Minio server or Cloud Storage. ")),(0,n.kt)("blockquote",{parentName:"li"},(0,n.kt)("p",{parentName:"blockquote"},"The MySQL database and the Minio server are both backed by the Kubernetes PersistentVolume subsystem. ")))),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Persistence agent and ML metadata: The Pipeline Persistence Agent watches the Kubernetes resources created by the Pipeline Service and persists the state of these resources in the ML Metadata Service. The Pipeline Persistence Agent records the set of containers that executed as well as their inputs and outputs. The input/output consists of either container parameters or data artifact URIs. ")),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Pipeline web server: The Pipeline web server gathers data from various services to display relevant views: the list of pipelines currently running, the history of pipeline execution, the list of data artifacts, debugging information about individual pipeline runs, execution status about individual pipeline runs ")),(0,n.kt)("h2",u({},{id:"pipelines-ui"}),"PIPELINES UI"),(0,n.kt)("h5",u({},{id:"open-pipelines-from-the-sidebar-to-see-the-different-sections-present-in-it"}),"Open pipelines from the sidebar to see the different sections present in it."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(79174).Z})),(0,n.kt)("h5",u({},{id:"the-following-sections-are-present-under-pipelines-"}),"The following sections are present under pipelines \u2013"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Experiment ")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Pipelines ")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Runs ")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Recurring Runs ")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Archive "))),(0,n.kt)("h2",u({},{id:"experiment"}),"Experiment"),(0,n.kt)("p",null,"An experiment is a workspace where you can try different configurations of your pipelines. You can use experiments to organize your runs into logical groups. Experiments can contain arbitrary runs, including recurring runs  "),(0,n.kt)("h4",u({},{id:"to-create-an-experiment-from-the-pipelines-ui"}),"To create an experiment from the Pipelines UI:"),(0,n.kt)("p",null,"i) Select Pipelines from the pop-up sidebar within the Pipelines section. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(67390).Z})),(0,n.kt)("p",null,"ii) You will see the list of all existing experiments. To create a new experiment, click on \u2018Create Experiment\u2019. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(87836).Z})),(0,n.kt)("p",null,"iii) On the \u2018Create Experiment\u2019 page, give your experiment a name and short description, and continue to click on next. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(99450).Z})),(0,n.kt)("p",null,"iv) On the next page, you can start a pipeline run within the experiment. To start a run, provide the run details (pipeline, pipeline version, run name, run type \u2013 one off or recurring) "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(25377).Z})),(0,n.kt)("p",null,"You can optionally click on \u2018Skip this step\u2019 to start a run at a later point. "),(0,n.kt)("p",null,"v) All the pipeline runs within an experiment can be viewed in the Experiment section. For each run, you can view its current status, duration for which it ran, the pipeline version, start time and whether it\u2019s a recurring run. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(41118).Z})),(0,n.kt)("h2",u({},{id:"pipelines"}),"Pipelines"),(0,n.kt)("p",null,"In this section, you can view all your existing pipelines and their different versions available. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(18630).Z})),(0,n.kt)("p",null,"You can also upload a pipeline from the Pipelines UI. "),(0,n.kt)("h4",u({},{id:"to-upload-a-pipeline"}),"To upload a pipeline:"),(0,n.kt)("p",null,"i) Click on Upload Pipeline "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(85597).Z})),(0,n.kt)("p",null,"ii) On the \u2018Upload Pipeline\u2019 page, you can create a new pipeline or create a new pipeline version under an existing pipeline. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(23062).Z})),(0,n.kt)("p",null,"iii) Give your pipeline a name and short description. Proceed to then upload a file or import by URL (package url or file must be in .yaml, .zip, or .tar.gz format), then click on \u2018Create\u2019 to finish uploading your pipeline. "),(0,n.kt)("p",null,"iv) Once the pipeline is created, you can view it under pipelines. Click on the pipeline to open the execution graph of the pipeline. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(33141).Z})),(0,n.kt)("p",null,"v) You can simplify the view by clicking on \u2018Simplify Graph\u2019 button. This enables a transitive reduction of the pipeline graph, hiding all the redundant edges. This option is just a visualization helper and does not have any permanent effect on the pipeline itself.  "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(51085).Z})),(0,n.kt)("p",null,"vi) You can create an experiment or directly create a pipeline run by selecting \u2018Create Experiment\u2019 or \u2018Create Run\u2019. "),(0,n.kt)("p",null,"vii) Clicking on \u2018Create Run\u2019 will take you to the next page where you can provide the run details (pipeline, pipeline version, run name, run type \u2013 one off or recurring) and then click on \u2018Start\u2019 to start the run. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(42731).Z})),(0,n.kt)("h2",u({},{id:"run"}),"Run"),(0,n.kt)("p",null,"A run is a single execution of a pipeline. Runs comprise an immutable log of all experiments that you attempt, and are designed to be self-contained to allow for reproducibility. You can track the progress of a run by looking at its details page on the Pipelines UI, where you can see the runtime graph, output artifacts, and logs for each step in the run. "),(0,n.kt)("h4",u({},{id:"to-create-a-run"}),"To create a run:"),(0,n.kt)("p",null,"i)  Navigate to Pipelines from the sidebar in the platform UI. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(50867).Z})),(0,n.kt)("p",null,"ii) Select Pipelines from the pop-up sidebar within the Pipelines section. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(63823).Z})),(0,n.kt)("p",null,"iii) Select the pipeline that you want to run from the list of existing pipelines. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(22115).Z})),(0,n.kt)("p",null,"iv) Select the version of the pipeline. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(26075).Z})),(0,n.kt)("p",null,"v) The pipeline graph will populate in the UI. Click on \u2018Create Run\u2019 to proceed. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(19845).Z})),(0,n.kt)("p",null,"vi) Clicking on \u2018Create Run\u2019 will take you to the next page where you can provide the run details (pipeline, pipeline version, run name, run type \u2013 one off or recurring) and then click on \u2018Start\u2019 to start the run. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(3854).Z})),(0,n.kt)("p",null,"vii) You can view the pipeline run progress from the runtime execution graph. "),(0,n.kt)("p",null,"A graph is a pictorial representation in the Pipelines UI of the runtime execution of a pipeline. The graph shows the steps that a pipeline run has executed or is executing, with arrows indicating the parent/child relationships between the pipeline components represented by each step. The graph is viewable as soon as the run begins. Each node within the graph corresponds to a step within the pipeline and is labelled accordingly. "),(0,n.kt)("p",null,"The screenshot below shows the example pipeline\u2019s runtime execution graph in the Pipelines UI: "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(79086).Z})),(0,n.kt)("p",null,"At the top right of each node is an icon indicating its status: running, succeeded, failed, or skipped. (A node can be skipped when its parent contains a conditional clause.) "),(0,n.kt)("h2",u({},{id:"recurring-run"}),"Recurring Run"),(0,n.kt)("p",null,"A recurring run, or job in the Pipelines backend APIs, is a repeatable run of a pipeline. The configuration for a recurring run includes a copy of a pipeline with all parameter values specified and a run trigger. You can start a recurring run inside any experiment, and it will periodically start a new copy of the run configuration. You can enable/disable the recurring run from the Pipelines UI. You can also specify the maximum number of concurrent runs, to limit the number of runs launched in parallel. This can be helpful if the pipeline is expected to run for a long period of time and is triggered to run frequently. "),(0,n.kt)("h4",u({},{id:"to-create-a-recurring-run"}),"To create a recurring run:"),(0,n.kt)("p",null,"i) When creating a run, select run type as \u2018Recurring\u2019 "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Untitled",src:i(85978).Z})),(0,n.kt)("p",null,"ii) Set the parameters for trigger type \u2013 Periodic or Cron, maximum concurrent runs and set the interval for each trigger in minutes, hours, days, weeks or months. You can also set start and end date for the recurring run by checking the \u2018Has start date\u2019 and \u2018Has end date\u2019 boxes, then setting the dates for each respectively. "),(0,n.kt)("p",null,"iii) Enable the \u2018Catchup\u2019 option to ensure whether the recurring run should catch up if behind schedule. Defaults to true. For example, if the recurring run is paused for a while and re-enabled afterwards. If catchup=true, the scheduler will catch up on (backfill) each missed interval. Otherwise, it only schedules the latest interval if more than one interval is ready to be scheduled. "),(0,n.kt)("p",null,"Usually, if your pipeline handles backfill internally, you should turn catchup off to avoid duplicate backfill. "),(0,n.kt)("h2",u({},{id:"archive"}),"Archive"),(0,n.kt)("p",null,"For runs, users can first archive and then delete archived runs. Note: only archived runs can be deleted from UI to avoid accidental deletion "),(0,n.kt)("p",null,"For experiments, users can archive experiments. We haven't enabled deletion of archived experiments in UI, because the current logic of deleting an experiment only deletes the experiment while leaving the runs inside the experiment intact, which will cause an issue when we render a run without an experiment in Run Details page. Therefore, we don't enable deletion of archived experiments for now.  "),(0,n.kt)("p",null,"Moreover, experiments don't take much space in our storage. Runs do. Therefore,\tdeletion of runs can free up a consideration amount of resources."))}k.isMDXComponent=!0},90571:function(e,t,i){t.Z=i.p+"assets/images/Pipeline1-3c71354a4de9745ce4b4b1333d803b75.png"},18630:function(e,t,i){t.Z=i.p+"assets/images/Pipeline10-217c47f4c71a369689e03e58e937d3e0.png"},85597:function(e,t,i){t.Z=i.p+"assets/images/Pipeline11-1766b860e76141239fd55e6974f930e2.png"},23062:function(e,t,i){t.Z=i.p+"assets/images/Pipeline12-737a2d265ce56aa8aef60d099e2ce298.png"},33141:function(e,t,i){t.Z=i.p+"assets/images/Pipeline13-86b58086dad717b29c8bd826fcf7f1e5.png"},51085:function(e,t,i){t.Z=i.p+"assets/images/Pipeline14-64b2ff4e5d768c08fbc72c201acf9830.png"},42731:function(e,t,i){t.Z=i.p+"assets/images/Pipeline15-8a61327cab51a37a42b32bd473bc37b6.png"},50867:function(e,t,i){t.Z=i.p+"assets/images/Pipeline16-83d568fd605602f1fc1c1178f6466402.png"},63823:function(e,t,i){t.Z=i.p+"assets/images/Pipeline17-6fe6eaa33c2e25f68935875818c4e373.png"},22115:function(e,t,i){t.Z=i.p+"assets/images/Pipeline18-4f43aef0d8d32f913ea3e50a502dc374.png"},26075:function(e,t,i){t.Z=i.p+"assets/images/Pipeline19-ef0ef7d2dc4c82dcf35f644c4ef355f7.png"},31332:function(e,t,i){t.Z=i.p+"assets/images/Pipeline2-d4027380bcf1238ef369870211c4b7e2.png"},19845:function(e,t,i){t.Z=i.p+"assets/images/Pipeline20-9ca322e076ffa135afb9371e0e440c71.png"},3854:function(e,t,i){t.Z=i.p+"assets/images/Pipeline21-8a61327cab51a37a42b32bd473bc37b6.png"},79086:function(e,t,i){t.Z=i.p+"assets/images/Pipeline22-3c71354a4de9745ce4b4b1333d803b75.png"},85978:function(e,t,i){t.Z=i.p+"assets/images/Pipeline23-76f50cddd434cb9090235a6918c870d9.png"},73954:function(e,t,i){t.Z=i.p+"assets/images/Pipeline3-1146c6c5cc7a6de3d65de1a878d5d8be.png"},79174:function(e,t,i){t.Z=i.p+"assets/images/Pipeline4-6fe6eaa33c2e25f68935875818c4e373.png"},67390:function(e,t,i){t.Z=i.p+"assets/images/Pipeline5-a932f9be48cdb98bcdbef6ced66bdb8e.png"},87836:function(e,t,i){t.Z=i.p+"assets/images/Pipeline6-02c1c0669074708219002b8eb73ce9fc.png"},99450:function(e,t,i){t.Z=i.p+"assets/images/Pipeline7-9d317f7266b02871ffb772c18124c2b3.png"},25377:function(e,t,i){t.Z=i.p+"assets/images/Pipeline8-0e345171c9898cc1bb8d4201777d2409.png"},41118:function(e,t,i){t.Z=i.p+"assets/images/Pipeline9-c8098e03eb46cf272b67587570a969df.png"}}]);